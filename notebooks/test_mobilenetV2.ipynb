{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36180a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaa1237c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples: 7178\n",
      "Classes: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = \"../fer2013\"\n",
    "TEST_DIR = f\"{DATA_ROOT}/test\"\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_dataset = datasets.ImageFolder(TEST_DIR, transform=transform_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Classes: {test_dataset.classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a73fa16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fine-tuned MobileNetV2 loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Recreate same model architecture\n",
    "mobilenet = models.mobilenet_v2(weights=None)\n",
    "num_ftrs = mobilenet.classifier[1].in_features\n",
    "mobilenet.classifier[1] = nn.Linear(num_ftrs, 7)\n",
    "\n",
    "# Load your fine-tuned weights\n",
    "mobilenet.load_state_dict(torch.load(\"../trained_models/mobilenetv2_finetuned.pth\", map_location=device))\n",
    "\n",
    "mobilenet = mobilenet.to(device)\n",
    "mobilenet.eval()\n",
    "\n",
    "print(\"✅ Fine-tuned MobileNetV2 loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "473e44bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test Accuracy of loaded MobileNetV2: 67.08%\n"
     ]
    }
   ],
   "source": [
    "correct, total = 0, 0\n",
    "mobilenet.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = mobilenet(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"✅ Test Accuracy of loaded MobileNetV2: {test_accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
